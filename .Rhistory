S <- solve(post_mode_result$hessian)
post_mode_result_df <- data.frame(
Mode = post_mode_result$mode,
Hessian_Diagonal = diag(post_mode_result$hessian),
S_Diagonal = diag(post_mode_result$S)
)
knitr::kable(post_mode_result_df, caption = "Posterior Mode Results")
log_like <- function(theta, x, y) {
beta1 <- theta[1]
beta2 <- theta[2]
beta3 <- exp(theta[3])
beta4 <- exp(theta[4])
mu <- beta1 + beta2 * x
sigma <- beta3 + beta4 * x^2
# Compute the log-likelihood for each observation
log_lik_vector <- dnorm(y, mean = mu, sd = sqrt(sigma), log = TRUE)
sum_log_lik <- sum(log_lik_vector)
return(sum_log_lik)
}
log_prior_density <- function(theta, params) {
# Extract the parameters
gamma1 <- params[1]
gamma2 <- params[2]
gamma3 <- params[3]
gamma4 <- params[4]
# Calculate the log prior density for each parameter
log_prior_theta1 <- dnorm(theta[1], mean = 0, sd = sqrt(gamma1), log = TRUE)
log_prior_theta2 <- dnorm(theta[2], mean = 1, sd = sqrt(gamma2), log = TRUE)
log_prior_theta3 <- dlogexp(exp(theta[3]), rate = gamma3, log = TRUE)
log_prior_theta4 <- dlogexp(exp(theta[4]), rate = gamma4, log = TRUE)
# Sum the log priors to get the joint log prior density
log_joint_prior <- log_prior_theta1 + log_prior_theta2 + log_prior_theta3 + log_prior_theta4
return(log_joint_prior)
}
#' log_like
#'
#' evaluate the observation log-likelihood p(y|theta) for a specified model,
#' taking into account the parameters theta and data points x and y
#' @param theta a numeric vector representing the parameters theta_1 to theta_4
#' @param x the independent variable
#' @param y the response variable
log_like <- function(theta, x, y) {
beta1 <- theta[1]
beta2 <- theta[2]
beta3 <- exp(theta[3])
beta4 <- exp(theta[4])
mu <- beta1 + beta2 * x
sigma <- beta3 + beta4 * x^2
# Compute the log-likelihood for each observation
log_lik_vector <- dnorm(y, mean = mu, sd = sqrt(sigma), log = TRUE)
sum_log_lik <- sum(log_lik_vector)
return(sum_log_lik)
}
#' log_posterior_density
#'
#' evaluates the logarithm of the posterior density p(theta|y)
#' @param theta a numeric vector representing the parameters theta_1 to theta_4
#' @param x the independent variable
#' @param y the response variable
log_posterior_density <- function(theta, x, y, params) {
# Compute the log-likelihood
log_lik <- log_like(theta, x, y)
# Compute the log-prior density
log_prior <- log_prior_density(theta, params)
# The log-posterior is the sum of the log-likelihood and log-prior
log_post <- log_lik + log_prior
return(log_post)
}
#' posterior_mode
#'
#' find the mode of the posterior distribution for a set of parameters and calculate the precision of these estimates.
#' It uses numerical optimization to maximize the log-posterior density, which is equivalent to minimizing
#' the negative log-posterior density due to the symmetry of optimization.
#'
#' @param theta_start A numeric vector representing the starting values for the parameters
#' @param x The independent variable CAD_Weight in filament1.
#' @param y The response variable Actual_Weight in filament1.
#' @param params A vector of additional parameters that are needed for calculating the log-posterior density.
posterior_mode <- function(theta_start, x, y, params) {
neg_log_posterior <- function(theta) -log_posterior_density(theta, x, y, params)
# Use optim to maximize the log-posterior density
optim_result <- optim(theta_start, neg_log_posterior, method = "BFGS", hessian = TRUE)
# Compute the inverse of the negated Hessian
S <- solve(-optim_result$hessian)
# Return a list with mode, Hessian, and S
return(list(mode = optim_result$par, hessian = optim_result$hessian, S = S))
}
# Assuming gamma values are all 1 for the approximation
params <- rep(1, 4)
# Initial theta values
theta_start <- rep(0, 4)
y <- filament1$Actual_Weight
x <- filament1$CAD_Weight
# Apply the posterior_mode function to find the mode and covariance matrix
post_mode_result <- posterior_mode(theta_start, x, y, params)
# The Gaussian approximation of the posterior is a multivariate normal with mean equal to the mode
# and covariance matrix equal to the inverse of the negated Hessian.
mu <- post_mode_result$mode
S <- solve(post_mode_result$hessian)
post_mode_result_df <- data.frame(
Mode = post_mode_result$mode,
Hessian_Diagonal = diag(post_mode_result$hessian),
S_Diagonal = diag(post_mode_result$S)
)
knitr::kable(post_mode_result_df, caption = "Posterior Mode Results")
log_prior_density <- function(theta, params) {
# Extract the parameters
gamma1 <- params[1]
gamma2 <- params[2]
gamma3 <- params[3]
gamma4 <- params[4]
# Calculate the log prior density for each parameter
log_prior_theta1 <- dnorm(theta[1], mean = 0, sd = sqrt(gamma1), log = TRUE)
log_prior_theta2 <- dnorm(theta[2], mean = 1, sd = sqrt(gamma2), log = TRUE)
log_prior_theta3 <- dlogexp(theta[3], rate = gamma3, log = TRUE)
log_prior_theta4 <- dlogexp(theta[4], rate = gamma4, log = TRUE)
# Sum the log priors to get the joint log prior density
log_joint_prior <- log_prior_theta1 + log_prior_theta2 + log_prior_theta3 + log_prior_theta4
return(log_joint_prior)
}
# Assuming gamma values are all 1 for the approximation
params <- rep(1, 4)
# Initial theta values
theta_start <- rep(0, 4)
y <- filament1$Actual_Weight
x <- filament1$CAD_Weight
# Apply the posterior_mode function to find the mode and covariance matrix
post_mode_result <- posterior_mode(theta_start, x, y, params)
# The Gaussian approximation of the posterior is a multivariate normal with mean equal to the mode
# and covariance matrix equal to the inverse of the negated Hessian.
mu <- post_mode_result$mode
S <- solve(post_mode_result$hessian)
post_mode_result_df <- data.frame(
Mode = post_mode_result$mode,
Hessian_Diagonal = diag(post_mode_result$hessian),
S_Diagonal = diag(post_mode_result$S)
)
knitr::kable(post_mode_result_df, caption = "Posterior Mode Results")
N <- 10000
importance_sample <- do_importance(N, mu, S, x = x, y = y, params = params)
sum(exp(importance_sample$log_weights))
samples_df <- as.data.frame(importance_sample)
samples_long <- samples_df %>%
pivot_longer(
cols = starts_with("beta"),
names_to = "parameter",
values_to = "value"
) %>%
group_by(parameter) %>%
arrange(value) %>%
mutate(
count = n(),
rank = row_number(),
unweighted_cdf = (rank - 1) / count,
weighted_cdf = cumsum(log_weights) / sum(log_weights)
) %>%
ungroup()
# Plot both CDFs
ggplot(samples_long) +
geom_step(aes(x = value, y = unweighted_cdf, color = "red"), linetype = "dashed") +
geom_step(aes(x = value, y = weighted_cdf, color = "blue")) +
facet_wrap(~parameter, scales = "free_x") +
labs(
title = "Weighted and Unweighted CDFs for Each Parameter",
x = "Parameter Value",
y = "CDF"
) +
theme_minimal() +
scale_linetype_manual(values = c("dashed", "solid"))
# Construct the credible intervals
cred_int <- data.frame(t(sapply(1:4, function(i) {
make_CI(importance_sample[[paste0("beta", i)]], importance_sample$log_weights, prob = 0.9)
})))
knitr::kable(cred_int, format = "html", caption = "90% Credible Intervals for Model Parameters")
# creates a sequence of x values for prediction
pred <- samples_df %>%
full_join(data.frame(x = seq(0, 100, by = 1)), by = character()) %>%
mutate(
mu = beta1 + beta2 * x,
sigma = sqrt(beta3 + beta4 * x^2),
weight = exp(log_weights)
) %>%
group_by(x) %>%
summarise(
mu_pred = sum(weight * mu),
sigma_pred = sqrt(sum(weight * (sigma^2 + (mu - mu_pred)^2))),
.groups = "drop"
)
# Plotting the prediction intervals
ggplot() +
geom_point(data = filament1, aes(x = CAD_Weight, y = Actual_Weight)) +
geom_line(data = pred, aes(x = x, y = mu_pred)) +
geom_ribbon(data = pred, aes(x = x, ymin = mu_pred - 2 * sigma_pred, ymax = mu_pred + 2 * sigma_pred), alpha = 0.2, inherit.aes = FALSE) +
labs(x = "CAD weight", y = "Actual weight", title = "Scatter plot with regression line and prediction intervals") +
theme_minimal()
ggplot(samples_long, aes(x = value, y = log_weights)) +
geom_point(alpha = 0.6) + # Use alpha to control point transparency
facet_wrap(~parameter) + # If you have multiple parameters, create a plot for each
labs(
title = "Importance Log-Weights by Sampled Beta Values",
x = "Sampled Beta Value",
y = "Importance Log-Weight"
) +
theme_minimal()
# Construct the credible intervals
cred_int <- data.frame(t(sapply(1:4, function(i) {
make_CI(importance_sample[[paste0("beta", i)]], importance_sample$log_weights, prob = 0.9)
})))
knitr::kable(cred_int, format = "html", caption = "90% Credible Intervals for Model Parameters")
make_CI <- function(x, weights, prob) {
quantiles <- quantile(x, probs = c((1 - prob)/2, 1 - (1 - prob)/2), type = 1, na.rm = FALSE, weights = weights)
data.frame(lower = quantiles[1], upper = quantiles[2])
}
# Construct the credible intervals
cred_int <- data.frame(t(sapply(1:4, function(i) {
make_CI(importance_sample[[paste0("beta", i)]], importance_sample$log_weights, prob = 0.9)
})))
knitr::kable(cred_int, format = "html", caption = "90% Credible Intervals for Model Parameters")
ggplot(samples_long, aes(x = value, y = log_weights)) +
geom_point(alpha = 0.6) + # Use alpha to control point transparency
facet_wrap(~parameter) + # If you have multiple parameters, create a plot for each
labs(
title = "Importance Log-Weights by Sampled Beta Values",
x = "Sampled Beta Value",
y = "Importance Log-Weight"
) +
theme_minimal()
make_CI <- function(x, weights, prob) {
# Ensure weights sum to 1
normalized_weights <- weights / sum(weights)
# Calculate the lower and upper bounds of the credible interval
CI_bounds <- wquantile(x, probs = c((1 - prob) / 2, 1 - (1 - prob) / 2),
na.rm = TRUE, type = 1, weights = normalized_weights)
# Return the credible interval as a data frame
data.frame(lower = CI_bounds[1], upper = CI_bounds[2])
}
# Construct the credible intervals
cred_int <- data.frame(t(sapply(1:4, function(i) {
make_CI(importance_sample[[paste0("beta", i)]], importance_sample$log_weights, prob = 0.9)
})))
knitr::kable(cred_int, format = "html", caption = "90% Credible Intervals for Model Parameters")
samples_df <- as.data.frame(importance_sample)
samples_long <- samples_df %>%
pivot_longer(
cols = starts_with("beta"),
names_to = "parameter",
values_to = "value"
) %>%
group_by(parameter) %>%
arrange(value) %>%
mutate(
count = n(),
rank = row_number(),
unweighted_cdf = (rank - 1) / count,
weighted_cdf = cumsum(log_weights) / sum(log_weights)
) %>%
ungroup()
# Plot both CDFs
ggplot(samples_long) +
geom_step(aes(x = value, y = unweighted_cdf, color = "red"), linetype = "dashed") +
geom_step(aes(x = value, y = weighted_cdf, color = "blue")) +
facet_wrap(~parameter, scales = "free_x") +
labs(
title = "Weighted and Unweighted CDFs for Each Parameter",
x = "Parameter Value",
y = "CDF"
) +
theme_minimal() +
scale_linetype_manual(values = c("dashed", "solid"))
# Assuming gamma values are all 1 for the approximation
params <- rep(1, 4)
# Initial theta values
theta_start <- rep(0, 4)
y <- filament1$Actual_Weight
x <- filament1$CAD_Weight
# Apply the posterior_mode function to find the mode and covariance matrix
post_mode_result <- posterior_mode(theta_start, x, y, params)
# The Gaussian approximation of the posterior is a multivariate normal with mean equal to the mode
# and covariance matrix equal to the inverse of the negated Hessian.
mu <- post_mode_result$mode
S <- solve(post_mode_result$hessian)
post_mode_result_df <- data.frame(
Mode = post_mode_result$mode,
Hessian_Diagonal = diag(post_mode_result$hessian),
S_Diagonal = diag(post_mode_result$S)
)
knitr::kable(post_mode_result_df, caption = "Posterior Mode Results")
params <- rep(1, 4)
# Initial theta values
theta_start <- rep(0, 4)
# the data points
y <- filament1$Actual_Weight
x <- filament1$CAD_Weight
# Apply the posterior_mode function to find the mode and covariance matrix
post_mode_result <- posterior_mode(theta_start, x, y, params)
mu <- post_mode_result$mode
S <- solve(post_mode_result$hessian)
post_mode_result_df <- data.frame(
Mode = post_mode_result$mode,
Hessian_Diagonal = diag(post_mode_result$hessian),
S_Diagonal = diag(post_mode_result$S)
)
knitr::kable(post_mode_result_df, caption = "Posterior Mode Results")
N <- 10000
importance_sample <- do_importance(N, mu, S, x = x, y = y, params = params)
sum(exp(importance_sample$log_weights))
# creates a sequence of x values for prediction
pred <- samples_df %>%
full_join(data.frame(x = seq(0, 100, by = 1)), by = character()) %>%
mutate(
mu = beta1 + beta2 * x,
sigma = sqrt(beta3 + beta4 * x^2),
weight = exp(log_weights)
) %>%
group_by(x) %>%
summarise(
mu_pred = sum(weight * mu),
sigma_pred = sqrt(sum(weight * (sigma^2 + (mu - mu_pred)^2))),
.groups = "drop"
)
# Plotting the prediction intervals
ggplot() +
geom_point(data = filament1, aes(x = CAD_Weight, y = Actual_Weight)) +
geom_line(data = pred, aes(x = x, y = mu_pred)) +
geom_ribbon(data = pred, aes(x = x, ymin = mu_pred - 2 * sigma_pred, ymax = mu_pred + 2 * sigma_pred), alpha = 0.2, inherit.aes = FALSE) +
labs(x = "CAD weight", y = "Actual weight", title = "Scatter plot with regression line and prediction intervals") +
theme_minimal()
ggplot(samples_long, aes(x = value, y = log_weights)) +
geom_point(alpha = 0.6) + # Use alpha to control point transparency
facet_wrap(~parameter) + # If you have multiple parameters, create a plot for each
labs(
title = "Importance Log-Weights by Sampled Beta Values",
x = "Sampled Beta Value",
y = "Importance Log-Weight"
) +
theme_minimal()
N <- 10000
importance_sample <- do_importance(N, mu, S, x = x, y = y, params = params)
sum(exp(importance_sample$log_weights))
samples_df <- as.data.frame(importance_sample)
samples_long <- samples_df %>%
pivot_longer(
cols = starts_with("beta"),
names_to = "parameter",
values_to = "value"
) %>%
group_by(parameter) %>%
arrange(value) %>%
mutate(
count = n(),
rank = row_number(),
unweighted_cdf = (rank - 1) / count,
weighted_cdf = cumsum(log_weights) / sum(log_weights)
) %>%
ungroup()
# Plot both CDFs
ggplot(samples_long) +
geom_step(aes(x = value, y = unweighted_cdf, color = "red"), linetype = "dashed") +
geom_step(aes(x = value, y = weighted_cdf, color = "blue")) +
facet_wrap(~parameter, scales = "free_x") +
labs(
title = "Weighted and Unweighted CDFs for Each Parameter",
x = "Parameter Value",
y = "CDF"
) +
theme_minimal() +
scale_linetype_manual(values = c("dashed", "solid"))
# Modify this setup code chunk to set options
# or add extra packages etc if needed.
# See the project instructions for more details
# on what code to show, and where/how.
# Load the data
load("filament1.rda")
# Discover the name of the variable
ls(filament1)
library(styler)
library(ggplot2)
library(dplyr)
style_file("report.Rmd", style = tidyverse_style)
# Set default code chunk options
knitr::opts_chunk$set(
echo = TRUE,
eval = TRUE
)
suppressPackageStartupMessages(library(tidyverse))
theme_set(theme_bw())
# To give the same random number sequence every time the document is knit:ed,
# making it easier to discuss the specific numbers in the text:
set.seed(12345L)
# Do not change this code chunk
# Load function definitions
source("code.R")
# Discover the name of the variable
ls(filament1)
# scatter plot is for observing the relationship between two continuous variables.
ggplot(filament1, aes(x = CAD_Weight, y = Actual_Weight)) +
geom_point() +
facet_wrap(~Material) +
theme_minimal() +
labs(
title = "Faceted Scatter Plot of CAD Weight vs Actual Weight",
x = "CAD Weight (grams)",
y = "Actual Weight (grams)"
)
# Box plots are great for visualizing the distribution of actual weight for each material
ggplot(filament1, aes(x = Material, y = CAD_Weight, fill = Material)) +
geom_boxplot() +
theme_minimal() +
labs(
title = "Box Plot of CAD Weight by Material",
x = "Material",
y = "CAD Weight (grams)"
)
fit_A <- filament1_estimate(filament1, "A")
fit_B <- filament1_estimate(filament1, "B")
# Compute confidence intervals for both models
ci_A <- compute_CI(fit_A)
ci_B <- compute_CI(fit_B)
# Print the results as a table using knitr::kable()
knitr::kable(ci_A, caption = "90% Confidence Intervals for Model A")
knitr::kable(ci_B, caption = "90% Confidence Intervals for Model B")
params <- rep(1, 4)
# Initial theta values
theta_start <- rep(0, 4)
# the data points
y <- filament1$Actual_Weight
x <- filament1$CAD_Weight
# Apply the posterior_mode function to find the mode and covariance matrix
post_mode_result <- posterior_mode(theta_start, x, y, params)
mu <- post_mode_result$mode
S <- solve(post_mode_result$hessian)
post_mode_result_df <- data.frame(
Mode = post_mode_result$mode,
Hessian_Diagonal = diag(post_mode_result$hessian),
S_Diagonal = diag(post_mode_result$S)
)
knitr::kable(post_mode_result_df, caption = "Posterior Mode Results")
N <- 10000
importance_sample <- do_importance(N, mu, S, x = x, y = y, params = params)
sum(exp(importance_sample$log_weights))
samples_df <- as.data.frame(importance_sample)
samples_long <- samples_df %>%
pivot_longer(
cols = starts_with("beta"),
names_to = "parameter",
values_to = "value"
) %>%
group_by(parameter) %>%
arrange(value) %>%
mutate(
count = n(),
rank = row_number(),
unweighted_cdf = (rank - 1) / count,
weighted_cdf = cumsum(log_weights) / sum(log_weights)
) %>%
ungroup()
# Plot both CDFs
ggplot(samples_long) +
geom_step(aes(x = value, y = unweighted_cdf, color = "red"), linetype = "dashed") +
geom_step(aes(x = value, y = weighted_cdf, color = "blue")) +
facet_wrap(~parameter, scales = "free_x") +
labs(
title = "Weighted and Unweighted CDFs for Each Parameter",
x = "Parameter Value",
y = "CDF"
) +
theme_minimal() +
scale_linetype_manual(values = c("dashed", "solid"))
# Construct the credible intervals
cred_int <- data.frame(t(sapply(1:4, function(i) {
make_CI(importance_sample[[paste0("beta", i)]], importance_sample$log_weights, prob = 0.9)
})))
knitr::kable(cred_int, format = "html", caption = "90% Credible Intervals for Model Parameters")
# creates a sequence of x values for prediction
pred <- samples_df %>%
full_join(data.frame(x = seq(0, 100, by = 1)), by = character()) %>%
mutate(
mu = beta1 + beta2 * x,
sigma = sqrt(beta3 + beta4 * x^2),
weight = exp(log_weights)
) %>%
group_by(x) %>%
summarise(
mu_pred = sum(weight * mu),
sigma_pred = sqrt(sum(weight * (sigma^2 + (mu - mu_pred)^2))),
.groups = "drop"
)
# Plotting the prediction intervals
ggplot() +
geom_point(data = filament1, aes(x = CAD_Weight, y = Actual_Weight)) +
geom_line(data = pred, aes(x = x, y = mu_pred)) +
geom_ribbon(data = pred, aes(x = x, ymin = mu_pred - 2 * sigma_pred, ymax = mu_pred + 2 * sigma_pred), alpha = 0.2, inherit.aes = FALSE) +
labs(x = "CAD weight", y = "Actual weight", title = "Scatter plot with regression line and prediction intervals") +
theme_minimal()
ggplot(samples_long, aes(x = value, y = log_weights)) +
geom_point(alpha = 0.6) + # Use alpha to control point transparency
facet_wrap(~parameter) + # If you have multiple parameters, create a plot for each
labs(
title = "Importance Log-Weights by Sampled Beta Values",
x = "Sampled Beta Value",
y = "Importance Log-Weight"
) +
theme_minimal()
ggplot(samples_long, aes(x = value, y = log_weights)) +
geom_point(alpha = 0.6) + # Use alpha to control point transparency
facet_wrap(~parameter) + # If you have multiple parameters, create a plot for each
labs(
title = "Importance Log-Weights by Sampled Beta Values",
x = "Sampled Beta Value",
y = "Importance Log-Weight"
) +
theme_minimal()
